import React, { useState, useRef, useEffect } from 'react';
import { Play, Pause, Mic2, Loader2 } from 'lucide-react';
import { generateAudioOverview } from '../services/geminiService';

interface AudioOverviewProps {
  topic: string;
  contextData: string;
}

// Helper to decode PCM and play (simplified for demo)
// In a real app, we might use a more robust WAV wrapper or AudioWorklet
const playPcmAudio = async (base64: string, audioContextRef: React.MutableRefObject<AudioContext | null>, sourceRef: React.MutableRefObject<AudioBufferSourceNode | null>, onEnded: () => void) => {
    try {
        const binaryString = atob(base64);
        const len = binaryString.length;
        const bytes = new Uint8Array(len);
        for (let i = 0; i < len; i++) {
            bytes[i] = binaryString.charCodeAt(i);
        }

        const ctx = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 24000 });
        audioContextRef.current = ctx;

        const dataInt16 = new Int16Array(bytes.buffer);
        const numChannels = 1;
        const frameCount = dataInt16.length; 
        const buffer = ctx.createBuffer(numChannels, frameCount, 24000);
        
        const channelData = buffer.getChannelData(0);
        for (let i = 0; i < frameCount; i++) {
            channelData[i] = dataInt16[i] / 32768.0;
        }

        const source = ctx.createBufferSource();
        source.buffer = buffer;
        source.connect(ctx.destination);
        source.onended = onEnded;
        source.start();
        sourceRef.current = source;
    } catch (e) {
        console.error("Error decoding audio", e);
        onEnded();
    }
};

export const AudioOverview: React.FC<AudioOverviewProps> = ({ topic, contextData }) => {
  const [audioData, setAudioData] = useState<string | null>(null);
  const [loading, setLoading] = useState(false);
  const [playing, setPlaying] = useState(false);
  
  const audioContextRef = useRef<AudioContext | null>(null);
  const sourceRef = useRef<AudioBufferSourceNode | null>(null);

  const handleGenerate = async () => {
    setLoading(true);
    try {
      const data = await generateAudioOverview(topic, contextData);
      setAudioData(data);
    } catch (e) {
      console.error(e);
      alert("Could not generate audio overview.");
    } finally {
      setLoading(false);
    }
  };

  const togglePlay = () => {
    if (playing) {
        if (sourceRef.current) {
            sourceRef.current.stop();
            sourceRef.current = null;
        }
        setPlaying(false);
    } else {
        if (audioData) {
            setPlaying(true);
            playPcmAudio(audioData, audioContextRef, sourceRef, () => setPlaying(false));
        }
    }
  };

  // Cleanup on unmount
  useEffect(() => {
      return () => {
          if (sourceRef.current) sourceRef.current.stop();
          if (audioContextRef.current) audioContextRef.current.close();
      };
  }, []);

  return (
    <div className="w-full max-w-3xl mx-auto bg-slate-900 border border-slate-800 rounded-2xl p-8 flex flex-col items-center text-center">
      <div className="w-20 h-20 bg-gradient-to-tr from-emerald-500 to-teal-400 rounded-full flex items-center justify-center shadow-lg shadow-emerald-500/20 mb-6">
        <Mic2 size={32} className="text-white" />
      </div>
      
      <h2 className="text-3xl font-bold text-white mb-2">Audio Overview</h2>
      <p className="text-slate-400 mb-8 max-w-md">
        Listen to a "Deep Dive" podcast conversation generated by AI about {topic}.
      </p>

      {!audioData && !loading && (
        <button 
            onClick={handleGenerate}
            className="px-8 py-3 bg-white text-slate-900 rounded-full font-bold hover:bg-slate-200 transition-colors flex items-center gap-2"
        >
            <Play size={18} fill="currentColor" />
            Generate Overview
        </button>
      )}

      {loading && (
        <div className="flex items-center gap-3 text-emerald-400">
            <Loader2 className="animate-spin" />
            <span className="font-mono text-sm">Synthesizing conversation...</span>
        </div>
      )}

      {audioData && (
        <div className="w-full max-w-md bg-slate-800 rounded-xl p-4 border border-slate-700 flex items-center gap-4">
            <button 
                onClick={togglePlay}
                className="w-12 h-12 flex-shrink-0 bg-emerald-500 hover:bg-emerald-400 text-white rounded-full flex items-center justify-center transition-colors"
            >
                {playing ? <Pause size={20} fill="currentColor" /> : <Play size={20} fill="currentColor" className="ml-1"/>}
            </button>
            <div className="flex-1">
                <div className="text-sm font-bold text-white mb-1">Deep Dive: {topic}</div>
                <div className="text-xs text-emerald-400 font-mono">Hosted by Gemini AI</div>
                {/* Fake Waveform */}
                <div className="mt-2 flex items-center gap-0.5 h-6">
                    {Array.from({ length: 30 }).map((_, i) => (
                        <div 
                            key={i} 
                            className={`flex-1 bg-slate-600 rounded-full transition-all duration-300 ${playing ? 'animate-pulse bg-emerald-500' : ''}`}
                            style={{ 
                                height: playing ? `${Math.random() * 100}%` : '20%',
                                animationDelay: `${i * 0.05}s`
                            }}
                        ></div>
                    ))}
                </div>
            </div>
        </div>
      )}
    </div>
  );
};